# Law ReImagined – 
# Inventing Automated and Autonomous Legal Entities

## Some remarks on "Legal Agent" status, "intent", and "control" in a specific context of Automated and Autonomous Systems (AAS): an "Inventor-AI".

DRAFT 20190806-0809 ChrisB unverified. Concepts, thought patterns & narratives may evolve.
Built on previous and current input from Team AALE, mistakes, confusions and omissions are ours (non-lawyer Chris) only.

**Creative Commons Attribution License: https://creativecommons.org/licenses/by/4.0/**

**Attribution: Christophe Bosquillon, MSc in cryptocurrency, digital assets & blockchain at the University of Nicosia, Cyprus (on-going). Also an alumni of Mines Paritech & HEC (Entrepreneurs) Paris.**


**Acronyms definition:**

**AALE:** Automated and Autonomous Legal Entity (the purpose of this MIT Media Lab Computational Law "AALE Challenge").

**AAS:** Automated and Autonomous Systems (including what is called an A.I. in various degrees of automation & autonomy).

**PID**: for Proportional–Integral–Derivative controller (PID controller, or three-term controller)- a control loop mechanism employing feedback that is widely used in industrial control systems and a variety of other applications requiring continuously modulated control. **PID-AAS:** an AAS mostly built on PID controllers.

**AI**: too loosely defined term- here it is used in the context of an "Inventor-AI", that was trained by its creator over 2 months using thousands of data sets including words and images, in order to produce increasingly complex concepts. The Inventor-AI ended up designing blueprints for objects doing functions, about which its creator _**had not previously introduced any specific background** (now we have your attention)._ **AI-AAS:** an AAS of that particular self-learning & creating kind.

**NPI:** Natural Person NP (as referred to in UK Patent Law) and/or Individual I (as referred to in US Patent Law).

**B/L/T/** Business/Legal/Technological/ construct that is the base-methodology approach for these AALEs design.

# 

**Clarifications & disclaimer:** (with thanks to Brenden for nailing the issues)

With respect to our overall AALE methodology & B/L/T/ construct, 
we yet have to see whether and how we integrate & utilize the outcome, if any, of the particular below discussion.

The purpose and modalities of the AALE Challenge are described in this Github repository. 
Further evolving processes and objectives are being developed in HackMD and in notes related to previous 3 Live Sessions 
(the curated content of which we're in the process of migrating to this Github repository).

_While we may not re-state these elements here, for the sake of not confusing our readers, here are some clarifications-_

Ultimately we are not talking about the design _**and**_ control of automated and autonomous systems with/by people 
(of AAS with/by NPI). What we are talking about is, _**the legal design constraints of such systems.**_

In other words, the question is here: _**how do you design these things in the context of a legal framework?**_  
Not only such design may only be considered as _**system-dependent**_ (by whom/whatever runs it)
& _**context-dependent**_ (the ecosystem it relates to within some specific implementation) ...

... but it is _**these legal design constraints that change system design and implementation itself.**_

Therefore the question is _**not**_ how do you design automated and autonomous systems that interact with people-

but _how do you design **and** control systems for Automated and Autonomous Legal Entities (AALEs)
that interact with humans (NPI) in the context of a legal framework._

It goes without saying that the billions of ubiquitous PID-controllers-built automated and autonomous systems (PID-AAS) 
are something that a subset of our engineer community has understood for more than half-a-century and knows how to do, 
from the Appolo 11 lunar lander to industrial automation to VR systems to an expresso machine.

_Thus our discussion here should **not** be construed as a discussion on humans (NPI) vs PID-AAS that already exist!_
 
_**However, there is an however-**_

The following deals with some other aspects of _**complexity, granularity, and "guaranteed rabbit holes",**_ 
a trinity that we already have encountered in our previous framing of legal analysis 
for "simple" business cases involving an AALE/DAO. 

It is part and parcel of our work here to develop methods to deal with this trinity.
In particular when faced with "guaranteed rabbit holes", which might be the case below, we like to have these "capped".

Until such right time that we might be in a position to deal with these efficiently, 
while involving the right people in the right place (or bring them to the place where they need to be).

_**A question that we think we should dare to ask-**_

Based on a case of "Inventor-AI" recently reported in the Financial Times, our (non-lawyer) primary intent here 
is to ponder the justification to ask the following question: 

_**"Could an Inventor-AI qualify for "Legal Agent" capacity & status?"**_ once you've established the fact that 
this Inventor-AI behaves independently from the background its creator has taught it in the first place, 
and start to autonomously create & invent blueprints for produceable objects that do certain functions.

Clearly this question is not about traditional PID-AAS interacting with humans (NPI). 
And it might come across as only indirectly related to our AALE Challenge, if at all- 

Nonetheless, this question has existing legal & ultimately Computational Law implications, that might be useful to consider- 
not only in this particular Inventor-AI context, but for wider & deeper AALEs consequences.

In particular, these issues of Inventor-AI Legal Agent, and, beyond that specific case of Inventor-AI, 
these issues of unclear definition & modalities of control 
between certain existing and/or upcoming types of AI-AAS & humans/NPI, these issues do exist.

They seem to remain only partially resolved from a B/L/T/ standpoint, in fact they're increasingly being challenged.

Furthermore, issues of "intent" and "control" do come back in the picture with a vengeance vis-à-vis current legal systems. 

There is this privileged link between the legal concept of “intent” and NPI, since “intent” doesn’t exist legally for an AAS, only for an NPI: that concept of "intent" is then deployed among various relevant bodies of Law. 

Then there is the issue of “control” between <non-PID-AAS> such as AI-AAS, and humans/NPI.

Both issues are so pivotal, since from these derive - among other things - 
the legal definiton of responsibility & liability 
(with concepts like a "crumple zone" possibly involving the nearest human/NPI etc).

So it turns out that we might use that little inventor-AI detour to hammer these points-
notwithstanding all other legal issues mentioned in our conversations.

(a kind of _Legal Möbius Strip_ comes to mind about how we're supposed to frame and structure these issues,
that might come back to haunt us in the design of AALEs as long as related legal systems do not evolve accordingly.)

Furthermore, we did put forward in previous sessions that our AALE design might want to include modalities 
where the AALE should be well-engineered (with AAS from advanced BPM systems to AI/ML etc.), 
so as to self-monitor & self-adjust at speed & data flows beyond human capacity to “control” it directly- 
even if the original design may remain itself a path to control. 

With respect to our overall AALE methodology & B/L/T/ construct, 
we yet have to see whether and how we integrate & utilize the outcome if any of the particular below discussion.
However we don’t seem to exonerate ourselves from dealing with these questions in due time & place. 

_**In a nutshell, with a formula by our AALE colleague Steve who pretty much encapsulates the whole thing:**_

### "... but this is really as much about _designing legal systems_ that make space for (AI-)AASs as much as it is about _designing (AI-)AASs_ so that they acquire attributes, features and behaviours that make them fit for the new legal systems.

### _Not every (AI-)AAS can be a Legal Agent; it will have to be designed for that purpose."_

#

## Law ReImagined – 
## Inventing Automated and Autonomous Legal Entities

### Some remarks on "Legal Agent" status, "intent", and "control" in a specific context of Automated and Autonomous Systems (AAS): an "Inventor-AI".

# 

#### Inventor-AI possible “Legal Agent” status


##### Financial Times piece [Patent Agencies Challenged to Accept AI inventor] (https://www.ft.com/content/9c114014-b373-11e9-bec9-fdcab53d6959)


##### **Fact 1:** Patent applications have been made by a team of legal experts for two designs (a plastic food container and a flashing light) **_made by a machine called Dabus._** 

That team is therefore asking patent regulatory authorities in the US and EU to acknowledge the legality of an AI (AAE) having legal capacity as an inventor in a patent application process.


##### **Fact 2:** The team, led by Ryan Abbott, professor of law and health sciences at the University of Surrey, submitted applications to the US Patent and Trademark Office, the European Patent Office, the UK Intellectual Property Office.

The UKIPO and EPO were informed that the “inventor” was a machine called **Dabus (“device for the autonomous bootstrapping of unified sentience”). Dabus was created by Missouri-based AI expert Dr Stephen Thaler.** Dr Thaler trained Dabus over 2 months using thousands of data sets including words and images, in order to produce increasingly complex concepts.  


##### **Fact 3:** as emphasized by Prof. Abbott and Dr. Thaler,   “What’s striking is that the machine invented in two very different areas, **_neither of which its programmer had any background in.”_**


##### **Fact 4:** Under the UK Patents Act 1977 and the European Patent Convention, **inventorship is restricted to _“natural persons” (NP)_**. **Likewise in the US, patent laws refer only to _“individuals” (I) as eligible inventors_**. 


##### **Fact 5:** [European Patent Office position on AI as "inventors"] (https://www.epo.org/news-issues/issues/ict/artificial-intelligence.html#study)

The study referred to in above FT piece, prepared by Dr. Noam Shemtov of Queen Mary University of London and a summary of the positions of the EPC contracting states can be downloaded through enclosed link, there are 3 documents:

-[A Study on Inventorship in Inventions Involving AI Activity, Dr Noam Shemtov - academic study (PDF, 470 KB)] (http://documents.epo.org/projects/babylon/eponet.nsf/0/3918F57B010A3540C125841900280653/$File/Concept_of_Inventorship_in_Inventions_involving_AI_Activity_en.pdf)

-[A Study on Inventorship in Inventions Involving AI Activity, Dr Noam Shemtov - presentation for the Patent Law Committee (PDF, 345 KB)] (http://documents.epo.org/projects/babylon/eponet.nsf/0/3918F57B010A3540C125841900280653/$File/AI_inventorship_presentation_en.pdf)

-[Legal aspects of patenting inventions involving artificial intelligence Summary of feedback by EPC contracting states (PDF, 345 KB)] (http://documents.epo.org/projects/babylon/eponet.nsf/0/3918F57B010A3540C125841900280653/$File/AI_inventorship_summary_of_answers_en.pdf)

_**In the words of the EPO:**_

>The current European legal framework is **_“suitable for addressing the inventorship . . . of inventions involving AI activity”_**, and machines, regardless of their intelligence, should be considered **_“tools”._** The EPO is _“aware of discussions” about AI and inventorship_, **_but reaffirmed its position that an inventor “can only be a person”._**

_**And in the words of Dr. Noam Shemtov:**_

>It is unlikely AI would advance to such a stage that it required changes in the law for **_“at least half a century”_**. **_“If and when we move to an era of AI systems possessing comprehensive knowledge and cognitive computing abilities, we will have to reassess our relationship with technology.”_**


##### **Fact 6:** Dabus’s patents currently under review by USPTO, EPO & UKIPO. Applications were also made with the WIPO.

-Initial stage of UKIPO’s patenting process has been passed with no further objections.

-The EPO sticks to above mentioned position.

-The USPTO, EPO and UKIPO would not comment on pending applications.  

-Applications with the WIPO World Intellectual Property Office, based in Geneva, are being filed first week of August 2019 (Prof Abbott). No further comment at this stage.


##### **Fact 7:** Prof Abbott _called for a new legal regime **“fit for purpose”**_.

Prof Abbott envisioned that these suggested legal regime changes would be likely to _**constitute an incentive for innovation across the global AI sector.**_ This in our view is _**a major aspect to consider in the build-up of a robust AA(L)E-based economy. In Prof Abbot’s words:**_

> **“If you make a point of recognizing how valuable a machine has been in the creative process, that machine will inevitably become more valuable.”**

This, to us, sounds like a very relevant and potent observation, from a business and economic standpoint, no doubt about it.

#

#### Discussion

_As pointed out by Dazza, if you put Fact 3 and Fact 5 in perspective …_

##### **Fact 3:** as emphasized by Prof. Abbott and Dr. Thaler,   “What’s striking is that the machine invented in two very different areas, **_neither of which its programmer had any background in.”_**

##### **Fact 5:** In the words of European Patent Office position on AI as "inventors":
>The current European legal framework is **_“suitable for addressing the inventorship . . . of inventions involving AI activity”_**, and machines, regardless of their intelligence, should be considered **_“tools”._** The EPO is _“aware of discussions” about AI and inventorship_, **_but reaffirmed its position that an inventor “can only be a person”._**

_… then you come to this inevitable conclusion- in Dazza’s words:_

>**When an object is inventing things for a user, (things) the user has no background in, (then) that object becomes much more than a controlled tool, and more like a phenomenon set in motion. _Dare I say it operates in some ways like a “Legal Agent”?**_

Our (Chris) comment:

>“... it operates in some way like a legal agent” then next thing to come to mind could be, if we apply that Agency framework, how to we define the Scope of Authority of said legal agent- in the context of its autonomous behavior as a “phenomenon set in motion” indeed much more than a tool fully “controlled” by the hand of its user/master. That gives us pause but at the same time it sounds like a valid & legitimate working topic: not just another out-on-a-limb AI speculation, since it has, after all, just now really happened. It’s real, folks.

_One Computational Law chat colleague Diana had a rather valid legal counterpoint (EPO), she said:_

>Going back to the concept of patents, as a right to exploit a given invention, it would be a problem to define “to whom” (legal person). This goes to _**legal personality**_ (even if companies are an abstract construction, in very narrow terms they’re also considered with personality rights (as _“name and credit”_). I am not so familiar with US patent law but in the case of trademarks (my experience) _**there is the need to assert the intent to use**_ (this would link to the core, genesis of the patent, a monopoly right granted by the State.. ). We also always need to consider the morals rights (ethical questions). I would go with EPO argument, _since a machine has no legal personality,_ so that would be a right attributed to no one... The case for companies or partnerships would be easier to get over with the “natural persons” approach.

_More original legal considerations by Diana, that we need to address and reflect on (language only slightly edited):_

>There are several issues. One is related to a domain, as words like "agents", "policies" have a context and we can´t remove them from all context (the way I refer to a policy in a given algorithm is different from law, or agent). 

>On the other extreme: animals, for the law (civil), are treated as "property", as a "thing", but we introduced the notion that we can´t do harm or cruelty to animals- but under the chapter of "things" (Germany also has it under the Civil Code). But because we can´t say an animal is a "legal person".

>Otherwise, setting as a person, brings all the rest (rights, duties...) (Chris comment: the R4 of legal analysis- Roles & Relationships, Rights & Responsibilities). If it's a free wild, animal, I am not responsible, but if the animal is mine ("property"), I am responsible for all that it does. 

>In automation, we may have objective responsibility (like when we drive a car...), considering "who is control" (then we can argue the level of direct control or not...). Also, we have these dual sides: personal vs overall interest, private versus common, rights versus duties, etc. The question is where we set the boundaries, but a right (as a patent) cannot exist without a subjective imputation (as we can´t have a right empty of content).  

Diana's thoughts are also put in perspective by Brenden, _and this bit appears below toward the end of the second part of this note: "More thoughts by Brenden in reply to Diana on the issue of "control" of AASs by NPIs or AI-AASs:"_, as it looks like that "control" axis is pivotal.

_We (non-lawyer Chris) venture below some further thoughts:_

_**remarks on issues of "intent" and "control" slightly extrapolated from this Inventor-AI case-_

Any extrapolation can be misleading, if premises are flawed or the larger scope is ill-defined, but we'll give it a stab-

So what do we have- an Inventor-AI that is an advanced form of automated & autonomous system (let's call it an AI-AAS, that is somehow an evolution stage beyond the established PID-AAS stage): indeed as a matter of fact rather than a legal opinion from a human standpoint, this Inventor-AI, it is not sentient nor self-aware, it is not a natural person nor and individual (not an NPI)- therefore _**it can not function within the paradigm of “intent” that first requires to be dealing with an NPI**, to be then deployed in relevant bodies of Law (Criminal, Contract, Tort, Trademark as also mentioned, etc.)._

Which connects back to the concept of “crumple zone” whereas the NPI most closely linked to the AI-AAS in the chain of events takes the blame for any consequences of the AI-AAS’s actions. 

In current & future larger & more complex AI-AAS set-ups, there is a risk that this AI-AAS-closest-NPI link becomes tenuous or even may not be possibly defined. Thus, there’s a risk of a legal vacuum developing fast (and in much less time than 50 years!) that makes it difficult to apply legal analysis methods & frameworks (same for ethical i.o. legal frameworks). 

This might provide sufficient justification to ask the (Dazza) question whereas the AI-AAS operates in same ways like a “Legal Agent”. Now if you would affix “Legal Agent” traits to this AI-AAS, legal analysis could be performed starting with where does the AI-AAS sits on the R4 mapping (Roles & Relationships, Rights and Responsibilities), etc.  

To take it one step further…

This Inventor-AI-AAS may be connected to a means of production (think deep-Space 3D-printing factory, whatever) that produces something. Then that something itself goes into AAE mode, and does things that have some impact over NPIs living in its vicinity- which leads us to what has been described under the concept of moral / ethical crumple zone: the nearest NPI in the chain of events & consequences takes the blame. 

But, that also connects back to the problematics of “Code is Free Speech” and “Code that exists sitting somewhere on a hardware means of electronic substrate is one thing, Code that is executing and doing the function that may have harmful consequences is another thing” (Brenden). (And which we could expand to “how about Code connected to a means of bionic or bio-neurocybernetic substrate linked to an extended NPI?”). 

In the Inventor-AI-and-patent example, the link to the closest NPIs in the chain of events (professor & his crew) is easy to establish, but it could become much more tenuous in larger contexts of AI-AASs.  So it could be logically argued that we run the risk of allowing for development of legal & ethical vacuums if we (lazily) bail ourselves out of the crumple zone by using the excuse of this increasingly tenuous connection to the nearest NPI. _**New, upgraded legal systems, will have to be built. To deny it sounds futile and slightly irresponsible, in the face of technological evolution and its deep societal impact**_

In other words, the possibility that such a connection exists and can still be seen as sufficient (to act as foundation to the legal & ethical analysis frameworks to be used), this assumed fact still may not exonerate ourselves from considering the relevance & utility to apply “Legal Agent” traits to this AI-AAS- even if it’s not an NPI itself that so far as retained the exclusive privilege of being legally endowed with the capacity of "intent". 

This (lazy) self-exoneration might feel even more wrong as AI-AAS develop cognitive & emotional communication protocols that make them look & feel much closer to an NPI (in a Stanley Kubrick et al. sort of ways), but it seems that in the current legal paradigm, there would still be ground to deny them Free Will and therefore “intent” and maintain them into status of “AI-AAS-tethered-to-NPI”.

_But then we develop that sort of paradox whereas, on one hand, **the notion of “constant control of AI-AAS by NPI” becomes increasingly irrelevant**, and on the other hand, **we still want to treat these AI-AAS as legally & ethically tethered to their remote creators & users NPI.**_  

We could ask whether this is analogous to like a kind of “Hillel ethical questioning” on the nature of AI-AASs and how they should proceed in the way they interact with their ecosystems.

But even if we think we don’t need to go that far yet, and we even don’t know how long we can entertain & indulge in that borderline complacent attitude (in any case we doubt it would take as long as 50 years), the mere fact that we have this vacuum developing fast, simply doesn’t exonerate ourselves _from at least considering the possibility of granting some degree of “Legal Agent” capacity and status to certain types of AI-AAS. This on condition that these AI-AAS be adequately engineered, in realtion with equally adequately engineered AALEs._ That doesn't sound too earth-shattering, as we soon enter the 2020's. 

It’s possible that we need some kind of reality-tsunami, brutally unleashed strings of unintended consequences, to start realizing that we can’t anymore deal with legal & ethical consequences of the actions of these AI-AASs by merely relying on the crumple zone’s tenuous connection to the nearest NPI. 

In any case, at some point, a good lawyer might be able to get the judge to exonerate à la Pontius Pilate even the closest NPI involved, and then we start washing our hands above some serious legal & ethical vacuum. 

_So, if this is sufficient to argue in favor of streamlining this vacuum, by outfitting this vacuum with a legal framework, then who/what else than this non-NPI AI-AAS should be affixed with the trait of a “Legal Agent” and its characteristics? Which isn't saying either that the Principal and the Third Party are NPIs only- they could be other AASs or AASs-extended NPIs, etc._

Then anyone involved may start pounding on this really nice working topic, and first we’d need to sort out the R4- Roles & Relationships, Rights & Responsibilities, for each party involved: where on the R4 mapping does an AI-AAS sit, that is also a “Legal Agent” etc. We can do charts and apply scenario permutations matrix, etc.

_This isn’t as weird and “fringe” legal analysis as it sounds._ Or maybe it is, and we (Chris) could be totally wrong, but methink it’s a no-brainer that at least some purposedly engineered AI-AASs may eventually be given some trait of “Legal Agent”, then we can see how our current legal & ethical frameworks pan out across existing jurisdictions. Or, alternatively, such purposedly engineered AI-AASs would have to be in some way re-attached to an AALE, and that AALE, which itself would have to be engineered accordingly, would be tackled either in the context of an existing Earth-based jurisdiction, or in any new legal localization, construct, and patterns remaining to be invented (think Space-based paradigms, more on this in later editions).

_**An interesting sub-plot,**_ could be whether and how could and should such AI-AAS-Legal-Agents be then permitted and regulated to practice NPI’s Law & ethical regulatory mechanisms among themselves …

… doing this at the kind of breadth, scope and speed scale warranted by AI-AAS intrinsic nature, and that an NPI wouldn’t be able to cope and deal with. Unless that NPI is extended (enhanced, augmented) by an AI-AAS properly engineered to these legal & ethical effects, in which case what are precisely the engineering specs for these effects. 

_**Next sub-plot,**_ whether and how should and could new legal & ethical frameworks be designed by AI-AAS to suit themselves (perhaps with some guidance from NPI in the early stages) and at the same time work in harmonious ways that are compatible with and supporting of NPI’s own (human) legal and ethical frameworks …

… and then, in order to achieve that, _**one obligated point of passage might be to sort out how the various bodies of (human) Law figure and converge in a B/L/T/ construct.**_

_And, in a sort of **advanced notion of B/L/T/ construct-based "checks and balances",** possibly also include contextual and in particular ethical regulatory frameworks, as a sort of (set of) additional (contextual fine tuning) functions on top of that B/L/T/ construct, in ways that are flexible, adaptable, evolutive, and most importantly, system- and context- dependent, built from the ground up, rather than arbitrarily super-imposed in a top-down fashion._

In Brenden’s words:
>At some point we will come to understand how the bodies of Law meet {computationally}

#

_**On some dangers of simplistic views of rules for machines in a context of legal & ethical "control" or lack thereof-**_

This below bit isn't related to above Inventor-AI-AAS example, _however the notion of control and rules for machine is._

We have had these discussions with Brenden a number of times, about the notions of _“controlling”_ or even _“intervening in the execution process”_ of AASs for example for legal and/or ethical purposes. This latest exchange was referring to this particular recent piece from a certain well-known MSM outlet [Tech Tent: Robot rules for any Tom, Dick or Harry] (https://www.bbc.co.uk/news/technology-49204682) but remarks apply to a larger context.

In Brenden’s words, that we (Chris) totally second:

>There is a problem with the simplistic view of rules for machines presented in the article.

>Certainly if we relied on the machine to be tethered to a human as the author suggests- we would have crashed the lunar module on the Moon’s surface.

>It is quite silly to suggest that a human be in control of all sorts of systems. Robotic, automated and autonomous systems, dynamic systems, often deal with a level of complexity beyond human capability. If you’re sending a rocket to the Space you’re not going to rely on a human to decide when to separate the rocket modules.

>Complex dynamic systems and especially ones that involve time, complex sensor systems and multiple decisions- are not suited to have rules that simply say we should be able to turn over control to humans at any point. This is in fact it dangerous.

>_The issue here is transfer of control to humans. But this is something that is system design and context dependent._

>Stating that we should have rules (statutes) around transfer control to humans- not only sets a dangerous precedent but legally compromises the millions (perhaps billions) of automated and autonomous systems currently operational.

>Transfer of control decisions can only be made by those who designed such systems- as these decisions are system dependent.

Further debunking that MSM piece mis-characterization with a metaphor used earlier, this would be equivalent to peering through the glass window at the door of a medical operation block, constantly telling the surgeon how (s)he should operate, at intervals of infinitesimal fractions of a second.

_**More thoughts by Brenden in reply to Diana on the issue of "control" of AASs by NPIs or AI-AASs:**_

>The challenge will be- that in the system as we are ever increasingly building are complex systems that will at times be under human control and at times be under control of an AI.

>But this is the simplified version- the reality of what is going to happen is that these systems will be indistinguishable. And at times only parts of certain systems will change control. It is going to become very difficult to separate out what we are currently calling AI from what is human.

>Much of this has to do with the bandwidth of the interfaces we use for computational entities- And more specifically the computational modalities we used to interface with these systems.

>If in one moment I am under control and then the next moment I gesture and the system is under control things become gray very quickly.....

>And this is nothing of the computational intelligence which will be enbedded into all of these systems. I could go on but I should probably stop while I’m ahead. (Or not).

_**So it looks like our AALE Team indeed has identified here some more pivotal axis:**_ 

... a notion of "Legal Agent" capacity and status for certain type of AI-AAS like the Inventor-AI, subject to proper engineering ;

... and - beyond PID-AAS - the notion, degree, & modalities of "intent" and "control" among interactions between AI-AAS and NPIs and AI-AAS-NPIs combined (extended, augmented, enhanced) ;

... all of this taking place within relevant legal system contexts, duly supported by AALEs ; 

... on mutual condition of proper B/L/T/ engineering for the AALEs and for the concerned AI-AAS ;

... especially those AI-AAS deemed to qualify for "Legal Agent" capacity & status ;

We yet have to see whether and how we integrate it & utilize it in our overall AALE methodology & construct... 

_**In a nutshell, with a formula by our AALE colleague Steve who pretty much encapsulates the whole thing:**_

### "... but this is really as much about _designing legal systems_ that make space for (AI-)AASs as much as it is about _designing (AI-)AASs_ so that they acquire attributes, features and behaviours that make them fit for the new legal systems.

### _Not every (AI-)AAS can be a Legal Agent; it will have to be designed for that purpose."_
